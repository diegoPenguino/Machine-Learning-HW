{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "13pL--6rycN3"
   },
   "source": [
    "## Homework02: Three headed network in PyTorch\n",
    "\n",
    "This notebook accompanies the [week02](https://github.com/girafe-ai/natural-language-processing/tree/master/week02_cnn_for_texts) practice session. Refer to that notebook for more comments.\n",
    "\n",
    "All the preprocessing is the same as in the classwork. *Including the data leakage in the train test split (it's still for bonus points).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P8zS7m-gycN5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import nltk\n",
    "import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have already downloaded the data on the Seminar, simply run through the next cells. Otherwise uncomment the next cell (and comment the another one ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment and run this cell, if you don't have data locally yet.\n",
    "\n",
    "# !curl -L \"https://www.dropbox.com/s/5msc5ix7ndyba10/Train_rev1.csv.tar.gz?dl=1\" -o Train_rev1.csv.tar.gz\n",
    "# !tar -xvzf ./Train_rev1.csv.tar.gz\n",
    "\n",
    "data = pd.read_csv(\"./Train_rev1.csv\", index_col=None)\n",
    "\n",
    "# !wget https://raw.githubusercontent.com/girafe-ai/natural-language-processing/22f_msai/homeworks/assignment02_three_headed_network/network.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "colab_type": "code",
    "id": "vwN72gd4ycOA",
    "outputId": "7b9e8549-3128-4041-c4be-33fb6f326c78"
   },
   "outputs": [],
   "source": [
    "# run this cell if you have downloaded the dataset on the seminar\n",
    "# data = pd.read_csv(\"../../week02_CNN_n_Vanishing_gradient/Train_rev1.csv\", index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "UuuKIKfrycOH",
    "outputId": "e5de0f94-a4f6-4b51-db80-9d11ddc1db31"
   },
   "outputs": [],
   "source": [
    "data['Log1pSalary'] = np.log1p(data['SalaryNormalized']).astype('float32')\n",
    "text_columns = [\"Title\", \"FullDescription\"]\n",
    "categorical_columns = [\"Category\", \"Company\", \"LocationNormalized\", \"ContractType\", \"ContractTime\"]\n",
    "target_column = \"Log1pSalary\"\n",
    "\n",
    "data[categorical_columns] = data[categorical_columns].fillna('NaN') # cast missing values to string \"NaN\"\n",
    "\n",
    "data.sample(3)\n",
    "\n",
    "data_for_autotest = data[-5000:]\n",
    "data = data[:-5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RUWkpd7PycOQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized:\n",
      "2         mathematical modeller / simulation analyst / o...\n",
      "100002    a successful and high achieving specialist sch...\n",
      "200002    web designer html , css , javascript , photosh...\n",
      "Name: FullDescription, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "239768it [00:35, 6697.07it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
    "# see task above\n",
    "def normalize(text):\n",
    "    text = str(text).lower()\n",
    "    return ' '.join(tokenizer.tokenize(text))\n",
    "    \n",
    "data[text_columns] = data[text_columns].applymap(normalize)\n",
    "\n",
    "print(\"Tokenized:\")\n",
    "print(data[\"FullDescription\"][2::100000])\n",
    "assert data[\"FullDescription\"][2][:50] == 'mathematical modeller / simulation analyst / opera'\n",
    "assert data[\"Title\"][54321] == 'international digital account manager ( german )'\n",
    "\n",
    "# Count how many times does each token occur in both \"Title\" and \"FullDescription\" in total\n",
    "# build a dictionary { token -> it's count }\n",
    "from collections import Counter\n",
    "from tqdm import tqdm as tqdm\n",
    "\n",
    "token_counts = Counter()\n",
    "\n",
    "for _, row in tqdm(data[text_columns].iterrows()):\n",
    "    for string in row:\n",
    "        token_counts.update(string.split())\n",
    "\n",
    "# hint: you may or may not want to use collections.Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('and', 2598827), ('.', 2471477), (',', 2266256), ('the', 2036428), ('to', 1977039), ('a', 1489358), ('of', 1394792), ('in', 1013586), ('for', 848605), ('with', 712923)]\n",
      "[('pharmaceutique', 1), ('mbcvwow', 1), ('lhcvwow', 1), ('infrasructure', 1), ('ncvwow', 1), ('vcvwow', 1), ('essentential', 1), ('dbms_stats', 1), ('dbms_output', 1), ('dbms_job', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(token_counts.most_common(10))\n",
    "print(token_counts.most_common()[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2598827"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_counts.most_common(1)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "colab_type": "code",
    "id": "GiOWbc15ycOb",
    "outputId": "1e807140-5513-4af0-d9a9-9f029059a553"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique tokens : 201127\n",
      "('and', 2598827)\n",
      "('.', 2471477)\n",
      "(',', 2266256)\n",
      "('the', 2036428)\n",
      "('to', 1977039)\n",
      "...\n",
      "('dbms_stats', 1)\n",
      "('dbms_output', 1)\n",
      "('dbms_job', 1)\n",
      "Correct!\n",
      "Vocabulary size: 33795\n",
      "Correct!\n",
      "Correct!\n"
     ]
    }
   ],
   "source": [
    "print(\"Total unique tokens :\", len(token_counts))\n",
    "print('\\n'.join(map(str, token_counts.most_common(n=5))))\n",
    "print('...')\n",
    "print('\\n'.join(map(str, token_counts.most_common()[-3:])))\n",
    "\n",
    "assert token_counts.most_common(1)[0][1] in  range(2500000, 2700000)\n",
    "assert len(token_counts) in range(200000, 210000)\n",
    "print('Correct!')\n",
    "\n",
    "min_count = 10\n",
    "\n",
    "# tokens from token_counts keys that had at least min_count occurrences throughout the dataset\n",
    "tokens = [token for token, count in token_counts.items() if count >= min_count]# <YOUR CODE HERE>\n",
    "# Add a special tokens for unknown and empty words\n",
    "UNK, PAD = \"UNK\", \"PAD\"\n",
    "tokens = [UNK, PAD] + sorted(tokens)\n",
    "print(\"Vocabulary size:\", len(tokens))\n",
    "\n",
    "assert type(tokens) == list\n",
    "assert len(tokens) in range(32000, 35000)\n",
    "assert 'me' in tokens\n",
    "assert UNK in tokens\n",
    "print(\"Correct!\")\n",
    "\n",
    "token_to_id = {token: idx for idx, token in enumerate(tokens)}\n",
    "assert isinstance(token_to_id, dict)\n",
    "assert len(token_to_id) == len(tokens)\n",
    "for tok in tokens:\n",
    "    assert tokens[token_to_id[tok]] == tok\n",
    "\n",
    "print(\"Correct!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JEsLeBjVycOw"
   },
   "outputs": [],
   "source": [
    "UNK_IX, PAD_IX = map(token_to_id.get, [UNK, PAD])\n",
    "\n",
    "def as_matrix(sequences, max_len=None):\n",
    "    \"\"\" Convert a list of tokens into a matrix with padding \"\"\"\n",
    "    if isinstance(sequences[0], str):\n",
    "        sequences = list(map(str.split, sequences))\n",
    "        \n",
    "    max_len = min(max(map(len, sequences)), max_len or float('inf'))\n",
    "    \n",
    "    matrix = np.full((len(sequences), max_len), np.int32(PAD_IX))\n",
    "    for i,seq in enumerate(sequences):\n",
    "        row_ix = [token_to_id.get(word, UNK_IX) for word in seq[:max_len]]\n",
    "        matrix[i, :len(row_ix)] = row_ix\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179
    },
    "colab_type": "code",
    "id": "JiBlPkdKycOy",
    "outputId": "3866b444-1e2d-4d79-d429-fecc6d8e02a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines:\n",
      "engineering systems analyst\n",
      "hr assistant\n",
      "senior ec & i engineer\n",
      "\n",
      "Matrix:\n",
      "[[10705 29830  2143     1     1]\n",
      " [14875  2817     1     1     1]\n",
      " [27345 10107    15 15069 10702]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Lines:\")\n",
    "print('\\n'.join(data[\"Title\"][::100000].values), end='\\n\\n')\n",
    "print(\"Matrix:\")\n",
    "print(as_matrix(data[\"Title\"][::100000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "DpOlBp7ZycO6",
    "outputId": "30a911f2-7d35-4cb5-8991-60457b1e8bac"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DictVectorizer(dtype=&lt;class &#x27;numpy.float32&#x27;&gt;, sparse=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DictVectorizer</label><div class=\"sk-toggleable__content\"><pre>DictVectorizer(dtype=&lt;class &#x27;numpy.float32&#x27;&gt;, sparse=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DictVectorizer(dtype=<class 'numpy.float32'>, sparse=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# we only consider top-1k most frequent companies to minimize memory usage\n",
    "top_companies, top_counts = zip(*Counter(data['Company']).most_common(1000))\n",
    "recognized_companies = set(top_companies)\n",
    "data[\"Company\"] = data[\"Company\"].apply(lambda comp: comp if comp in recognized_companies else \"Other\")\n",
    "\n",
    "categorical_vectorizer = DictVectorizer(dtype=np.float32, sparse=False)\n",
    "categorical_vectorizer.fit(data[categorical_columns].apply(dict, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yk4jmtAYycO8"
   },
   "source": [
    "### The deep learning part\n",
    "\n",
    "Once we've learned to tokenize the data, let's design a machine learning experiment.\n",
    "\n",
    "As before, we won't focus too much on validation, opting for a simple train-test split.\n",
    "\n",
    "__To be completely rigorous,__ we've comitted a small crime here: we used the whole data for tokenization and vocabulary building. A more strict way would be to do that part on training set only. You may want to do that and measure the magnitude of changes.\n",
    "\n",
    "\n",
    "#### Here comes the simple one-headed network from the seminar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "TngLcWA0ycO_",
    "outputId": "6731b28c-07b1-41dc-9574-f76b01785bba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size =  191814\n",
      "Validation size =  47954\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train, data_val = train_test_split(data, test_size=0.2, random_state=42)\n",
    "data_train.index = range(len(data_train))\n",
    "data_val.index = range(len(data_val))\n",
    "\n",
    "print(\"Train size = \", len(data_train))\n",
    "print(\"Validation size = \", len(data_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2PXuKgOSycPB"
   },
   "outputs": [],
   "source": [
    "def make_batch(data, max_len=None, word_dropout=0):\n",
    "    \"\"\"\n",
    "    Creates a keras-friendly dict from the batch data.\n",
    "    :param word_dropout: replaces token index with UNK_IX with this probability\n",
    "    :returns: a dict with {'title' : int64[batch, title_max_len]\n",
    "    \"\"\"\n",
    "    batch = {}\n",
    "    batch[\"Title\"] = as_matrix(data[\"Title\"].values, max_len)\n",
    "    batch[\"FullDescription\"] = as_matrix(data[\"FullDescription\"].values, max_len)\n",
    "    batch['Categorical'] = categorical_vectorizer.transform(data[categorical_columns].apply(dict, axis=1))\n",
    "    \n",
    "    if word_dropout != 0:\n",
    "        batch[\"FullDescription\"] = apply_word_dropout(batch[\"FullDescription\"], 1. - word_dropout)\n",
    "    \n",
    "    if target_column in data.columns:\n",
    "        batch[target_column] = data[target_column].values\n",
    "    \n",
    "    return batch\n",
    "\n",
    "def apply_word_dropout(matrix, keep_prop, replace_with=UNK_IX, pad_ix=PAD_IX,):\n",
    "    dropout_mask = np.random.choice(2, np.shape(matrix), p=[keep_prop, 1 - keep_prop])\n",
    "    dropout_mask &= matrix != pad_ix\n",
    "    return np.choose(dropout_mask, [matrix, np.full_like(matrix, replace_with)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251
    },
    "colab_type": "code",
    "id": "I6LpEQf0ycPD",
    "outputId": "e3520cae-fba1-46cc-a216-56287b6e4929"
   },
   "outputs": [],
   "source": [
    "a = make_batch(data_train[:3], max_len=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But to start with let's build the simple model using only the part of the data. Let's create the baseline solution using only the description part (so it should definetely fit into the Sequential model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You will need these to make it simple\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "class Reorder(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.permute((0, 2, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate minibatches we will use simple pyton generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_minibatches(data, batch_size=256, shuffle=True, cycle=False, **kwargs):\n",
    "    \"\"\" iterates minibatches of data in random order \"\"\"\n",
    "    while True:\n",
    "        indices = np.arange(len(data))\n",
    "        if shuffle:\n",
    "            indices = np.random.permutation(indices)\n",
    "\n",
    "        for start in range(0, len(indices), batch_size):\n",
    "            batch = make_batch(data.iloc[indices[start : start + batch_size]], **kwargs)\n",
    "            target = batch.pop(target_column)\n",
    "            yield batch, target\n",
    "        \n",
    "        if not cycle: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = iterate_minibatches(data_train, 3)\n",
    "batch, target = next(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is some startup code:\n",
    "n_tokens=len(tokens)\n",
    "n_cat_features=len(categorical_vectorizer.vocabulary_)\n",
    "hid_size=64\n",
    "simple_model = nn.Sequential()\n",
    "\n",
    "simple_model.add_module('emb', nn.Embedding(num_embeddings=n_tokens, embedding_dim=hid_size))\n",
    "simple_model.add_module('reorder', Reorder())\n",
    "simple_model.add_module('conv1', nn.Conv1d(\n",
    "    in_channels=hid_size,\n",
    "    out_channels=hid_size,\n",
    "    kernel_size=2)\n",
    "                       )\n",
    "simple_model.add_module('relu1', nn.ReLU())\n",
    "simple_model.add_module('adapt_avg_pool', nn.AdaptiveAvgPool1d(output_size=1))\n",
    "simple_model.add_module('flatten1', Flatten())\n",
    "simple_model.add_module('linear1', nn.Linear(in_features=hid_size, out_features=1))\n",
    "simple_model.add_module('flatten2', Flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Title': array([[ 5030,   147,  8997,  7338,  3716,     1,     1],\n",
       "        [24093, 18670,    32, 29657, 31132, 24114,    63],\n",
       "        [ 7706,    80,     0,     1,     1,     1,     1]]),\n",
       " 'FullDescription': array([[ 5030,   195,  5030,   147,  8997, 25722,  7338, 23421, 30411,\n",
       "          6347,   891, 32047, 24821, 16378, 33331, 15402,  7140, 33198,\n",
       "         21972, 23815,  6347,  3512, 15402, 30411, 14256, 21405, 30411,\n",
       "          6200,  5722, 33198,  2120, 16006, 23774, 16289,  8091, 25110,\n",
       "         12466,   965, 21196, 21405,  7338, 23415, 30762, 33306, 21556,\n",
       "           965, 24786, 21405,  8090,  2166, 20697, 24114,   167, 25861,\n",
       "           891,  9000, 21405, 24015, 31946,  5030,  2166,  5030,   147,\n",
       "         21556,   965, 31737, 10866,   167, 30411, 15142, 22789,   891,\n",
       "            32, 11068,    63,  8664,    32, 19638,    97, 15402,  6990,\n",
       "         26982,   156, 28294,   156, 10364, 21784, 10387, 10705, 21784,\n",
       "         21950, 25440,  9285,   167, 23574,   156, 25476, 11453, 15402,\n",
       "         30411,  8894,  2166,  9000, 21405, 25801,   156, 14452,   156,\n",
       "         18321, 28294, 28350, 31962,  5030, 21784,  5030,   147, 15402,\n",
       "           965, 17979,   195, 31737, 10866,   167, 25558,   891, 11419,\n",
       "          8275, 24818, 21405,  3864,    80, 30762,    80, 12466, 12913,\n",
       "         15652, 23212,  7280,  6095,  3049, 15402, 30411, 29203,  7088,\n",
       "         21556,    80,    80,    80, 21784,  2395, 32230, 30411, 17958,\n",
       "         21556, 30512, 22203,   167,    32, 15187, 33635, 14109, 12579,\n",
       "         33642,  8167, 30762, 32055, 33209, 30411, 17451,   555, 19947,\n",
       "         23212,  9526, 21084,  2395,  2662, 21972, 28537,  7253,  2545,\n",
       "          3189, 21405, 33642,  3136,   167, 15187, 33635, 33403, 17898,\n",
       "         30762,  7280, 32055, 12466,  2120, 31827, 23212,  5124, 21972,\n",
       "          7253,  9238, 21556,    80,    80,    97],\n",
       "        [16658, 30725,   891, 24093, 18670,    32, 29657, 31132, 24114,\n",
       "            63, 18132,   891,  5160,  9939,   891,   692, 19947, 33635,\n",
       "         33079,  3607, 22347, 21405, 30411, 31132, 15671, 29160, 30080,\n",
       "           167, 30411, 30080, 16289, 25867, 12466,  8998, 30411,  7648,\n",
       "            18, 26612, 31132,  2166, 15671, 29154,  2166, 23153, 32971,\n",
       "         31632, 31132,  8715,  2166, 30411, 13717,  1679,   167, 16658,\n",
       "          9951, 15444,   891, 24093,  2166, 24071, 18664, 12466, 31132,\n",
       "         24114, 10781, 24114,  2545,  8709, 21556, 30654,  2166, 33209,\n",
       "          4808, 29566, 29160,  9000, 12105, 22095,   195,  6231, 24079,\n",
       "         31829,   156, 25672, 11068,  7856,   891,  1041, 30762, 24093,\n",
       "         18659,   156, 30762, 23137,  2166, 15352, 19918, 24114,  2166,\n",
       "         24076,  2166, 18659, 12105,  6231,  2166, 25672,  8664, 21784,\n",
       "         10958, 15402,   965, 31132, 21784, 25440, 12023, 23876, 15216,\n",
       "         12600, 24555, 21784, 10958, 19037, 20573, 30762, 31151, 30762,\n",
       "         22377,  3084, 21784, 27956, 33209, 30411,  7648, 30407, 19037,\n",
       "         21084,  3607,  1130,  5016, 24343, 31132,   167, 28843,  7777,\n",
       "         33403,  3607, 15142, 14860, 21084, 11068,  2662, 33079,  3607,\n",
       "         31649,  5016,  1675,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1],\n",
       "        [32718, 25721,  2120, 11458, 13696, 30407, 14638,  2120, 15402,\n",
       "          8381,    80,  1059,  2166,  3742,    80, 30821,  7706, 17845,\n",
       "           167, 20357, 14109, 11453, 33331, 33198,  7052,   167,    80,\n",
       "           555, 19947, 23248, 33306, 12466, 30411, 26139,  5221,   167,\n",
       "         23212,  5124, 28577, 21556,    80,  2166,  2729, 12466, 22937,\n",
       "         18903,   167,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1]]),\n",
       " 'Categorical': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remember!__ We are working with regression problem and predicting only one number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2261],\n",
       "        [0.2961],\n",
       "        [0.4636]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try this to check your model. `torch.long` tensors are required for nn.Embedding layers.\n",
    "simple_model(torch.tensor(batch['FullDescription'], dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 204)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['FullDescription'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now simple training pipeline (it's commented because we've already done that in class. No need to do it again)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from random import sample\n",
    "\n",
    "epochs = 1\n",
    "\n",
    "model = simple_model\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "history = []\n",
    "for epoch_num in range(epochs):\n",
    "    for idx, (batch, target) in enumerate(iterate_minibatches(data_train)):\n",
    "        # Preprocessing the batch data and target\n",
    "        batch = torch.tensor(batch['FullDescription'], dtype=torch.long)\n",
    "\n",
    "        target = torch.tensor(target)\n",
    "\n",
    "\n",
    "        predictions = model(batch)\n",
    "        predictions = predictions.view(predictions.size(0))\n",
    "\n",
    "        loss = loss_func(predictions, target)# <YOUR CODE HERE>\n",
    "\n",
    "        # train with backprop\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        # <YOUR CODE HERE>\n",
    "\n",
    "        history.append(loss.data.numpy())\n",
    "        if (idx+1)%10==0:\n",
    "            clear_output(True)\n",
    "            plt.plot(history,label='loss')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "        if loss < 0.5 and idx > 100:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual homework starts here\n",
    "__Your ultimate task is to code the three headed network described on the picture below.__ \n",
    "To make it closer to the real world, please store the network code in file `network.py` in this directory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0eI5h9UMycPF"
   },
   "source": [
    "#### Architecture\n",
    "\n",
    "Our main model consists of three branches:\n",
    "* Title encoder\n",
    "* Description encoder\n",
    "* Categorical features encoder\n",
    "\n",
    "We will then feed all 3 branches into one common network that predicts salary.\n",
    "\n",
    "<img src=\"https://github.com/yandexdataschool/nlp_course/raw/master/resources/w2_conv_arch.png\" width=600px>\n",
    "\n",
    "This clearly doesn't fit into PyTorch __Sequential__ interface. To build such a network, one will have to use [__PyTorch nn.Module API__](https://pytorch.org/docs/stable/nn.html#torch.nn.Module)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'network' from 'c:\\\\Users\\\\diego\\\\Documents\\\\GitHub\\\\Machine-Learning-HW\\\\Spring_semester\\\\assignment02_three_headed_network\\\\network.py'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-run this cell if you updated the file with network source code\n",
    "import imp\n",
    "imp.reload(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 10)\n",
      "(3, 3746)\n",
      "(3, 8)\n"
     ]
    }
   ],
   "source": [
    "batch = make_batch(data_train[:3], max_len=10)\n",
    "print(batch['FullDescription'].shape)\n",
    "print(batch['Categorical'].shape)\n",
    "print(batch['Title'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = network.ThreeInputsNet(\n",
    "    n_tokens=len(tokens),\n",
    "    n_cat_features=len(categorical_vectorizer.vocabulary_),\n",
    "\n",
    "    # this parameter defines the number of the inputs in the layer,\n",
    "    # which stands after the concatenation. In should be found out by you.\n",
    "    concat_number_of_features=64*9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_batch, _ = next(iterate_minibatches(data_train, 3))\n",
    "testing_batch = [\n",
    "    torch.tensor(testing_batch['Title'], dtype=torch.long),\n",
    "    torch.tensor(testing_batch['FullDescription'], dtype=torch.long),\n",
    "    torch.tensor(testing_batch['Categorical'])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seems fine!\n"
     ]
    }
   ],
   "source": [
    "assert model(testing_batch).shape == torch.Size([3, 1])\n",
    "assert model(testing_batch).dtype == torch.float32\n",
    "print('Seems fine!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train the network for a while (100 batches would be fine)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from random import sample\n",
    "\n",
    "epochs = 1\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "history = []\n",
    "for epoch_num in range(epochs):\n",
    "    for idx, (batch, target) in enumerate(iterate_minibatches(data_train)):\n",
    "        # Preprocessing the batch data and target\n",
    "        batch = [\n",
    "            torch.tensor(batch['Title'], dtype=torch.long),\n",
    "            torch.tensor(batch['FullDescription'], dtype=torch.long),\n",
    "            torch.tensor(batch['Categorical'])\n",
    "        ]\n",
    "\n",
    "        target = torch.tensor(target)\n",
    "        \n",
    "        predictions = model(batch)\n",
    "        predictions = predictions.view(predictions.size(0))\n",
    "\n",
    "        loss = loss_func(predictions, target)\n",
    "\n",
    "        # train with backprop\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "        history.append(loss.data.numpy())\n",
    "        if (idx+1)%5==0:\n",
    "            clear_output(True)\n",
    "            plt.plot(history,label='loss')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "        if loss < 0.2 and idx > 100:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to evaluate the model it can be switched to `eval` state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ThreeInputsNet(\n",
       "  (title_emb): Embedding(33795, 64)\n",
       "  (title_nn): Sequential(\n",
       "    (0): Conv1d(64, 192, kernel_size=(3,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): AdaptiveAvgPool1d(output_size=1)\n",
       "  )\n",
       "  (full_emb): Embedding(33795, 64)\n",
       "  (desc_nn): Sequential(\n",
       "    (0): Conv1d(64, 192, kernel_size=(3,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): AdaptiveAvgPool1d(output_size=1)\n",
       "  )\n",
       "  (category_out): Sequential(\n",
       "    (0): Linear(in_features=3746, out_features=192, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (inter_dense): Linear(in_features=576, out_features=192, bias=True)\n",
       "  (final_dense): Linear(in_features=192, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission(model, data, batch_size=256, name=\"\", three_inputs_mode=True, **kw):\n",
    "    squared_error = abs_error = num_samples = 0.0\n",
    "    output_list = []\n",
    "    for batch_x, batch_y in tqdm(iterate_minibatches(data, batch_size=batch_size, shuffle=False, **kw)):\n",
    "        if three_inputs_mode:\n",
    "            batch = [\n",
    "                torch.tensor(batch_x['Title'], dtype=torch.long),\n",
    "                torch.tensor(batch_x['FullDescription'], dtype=torch.long),\n",
    "                torch.tensor(batch_x['Categorical'])\n",
    "            ]\n",
    "        else:\n",
    "            batch = torch.tensor(batch_x['FullDescription'], dtype=torch.long)\n",
    "\n",
    "        batch_pred = model(batch)[:, 0].detach().numpy()\n",
    "        \n",
    "        output_list.append((list(batch_pred), list(batch_y)))\n",
    "        \n",
    "        squared_error += np.sum(np.square(batch_pred - batch_y))\n",
    "        abs_error += np.sum(np.abs(batch_pred - batch_y))\n",
    "        num_samples += len(batch_y)\n",
    "    print(\"%s results:\" % (name or \"\"))\n",
    "    print(\"Mean square error: %.5f\" % (squared_error / num_samples))\n",
    "    print(\"Mean absolute error: %.5f\" % (abs_error / num_samples))\n",
    "    \n",
    "\n",
    "    batch_pred = [c for x in output_list for c in x[0]]\n",
    "    batch_y = [c for x in output_list for c in x[1]]\n",
    "    output_df = pd.DataFrame(list(zip(batch_pred, batch_y)), columns=['batch_pred', 'batch_y'])\n",
    "    output_df.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:06,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission results:\n",
      "Mean square error: 0.27983\n",
      "Mean absolute error: 0.41837\n",
      "Submission file generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generate_submission(model, data_for_autotest, name='Submission')\n",
    "print('Submission file generated')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Both the notebook and the `.py` file are required to submit this homework.__"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "CNN_for_texts.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
